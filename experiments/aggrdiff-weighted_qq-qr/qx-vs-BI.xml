<!-- 
	This can be used to train player 2 against MM or MR resulting policy.
	We just need to specify which policy to be loaded by player 1 via
	command line
-->

<experiment>
	<parameters>
		<episodes value="100" />
		<game-duration value="3000" /> 
		<abstraction-model value="aggregatediff" />
		<output-dir value="/tmp/results" />
		<reward-function value="simpleweighted" />
		<quiet-learning value="true" />
	</parameters>

	<player name="QLearning" type="SGQLearningAdapter">
		<discount value='0' />
		<learning-rate type='constant' value='0' />
		<initial-q value='0' />
		<epsilon value='0' />
		<!-- <path-to-knowledge value="specify/via/cmd/line" /> -->
	</player>

	<player name="BI" type="BackwardInduction">
		<path-to-knowledge value="/tmp/solution.xml" /> <!-- make sure it exists or you'll be in trouble -->
	</player>

</experiment>
